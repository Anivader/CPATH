{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c4b4aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyvips   # create image pyramid from tiles\n",
    "from openslide import open_slide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tifffile as tiff   # we want to write/handle our images as \"TIFF\"\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c4fc5b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n",
      "Saving images for quantitative analysis ...\n",
      "WSI imageset created !\n"
     ]
    }
   ],
   "source": [
    "### Save normalized image tiles at all levels for all patient WSIs\n",
    "# We also want to sort the images into \"Strong_signal\" and \"Weak_signal\"\n",
    "\n",
    "# Get list of all patient WSIs\n",
    "dir_name = \"/Users/anirudhgangadhar/Desktop/UHN_Postdoc/Datasets/Liver_biopsy_patient_images/\"\n",
    "wsi_img_list=(glob.glob(dir_name + \"*.svs\"))\n",
    "\n",
    "# Change path to wherever you want to store the image tiles\n",
    "os.chdir('/Users/anirudhgangadhar/Desktop/UHN_Postdoc/Data and results/Liver_biopsy/Patient image sets/')\n",
    "for i in range(len(wsi_img_list)): \n",
    "    \n",
    "    # if we want to test for 1 WSI case \n",
    "#     if i == 1:\n",
    "#         break\n",
    "    \n",
    "    # Get WSI filename w/o extension - we will use this to name folders\n",
    "    filename_noext = os.path.splitext(os.path.basename(wsi_img_list[i]))[0]\n",
    "    \n",
    "    # Create unique folder for patient\n",
    "    parent_dir = '/Users/anirudhgangadhar/Desktop/UHN_Postdoc/Data and results/Liver_biopsy/Patient image sets/'\n",
    "    directory = filename_noext\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    \n",
    "    # check if directory exists already - if so don't create new directory\n",
    "    if os.path.exists(path) == False:\n",
    "        \n",
    "        print(f'Saving WSI: {filename_noext} for quantitative analysis ...')\n",
    "        os.mkdir(path)\n",
    "    \n",
    "        # Create sub-folders for different tile levels\n",
    "        # Read WSI image\n",
    "        slide = open_slide(wsi_img_list[i])\n",
    "    \n",
    "        tile_sz = 256\n",
    "        tiles = DeepZoomGenerator(slide, tile_size=tile_sz, overlap=0, limit_bounds=False)\n",
    "        num_levels = tiles.level_count\n",
    "        \n",
    "        # Create folder for each tile level\n",
    "        for j in range(15):  # All levels will generate too may images\n",
    "            cols, rows = tiles.level_tiles[j]\n",
    "            # First, create unique folder for each tile level\n",
    "            path_level = os.path.join(path, '%d' % j)\n",
    "            os.mkdir(path_level)\n",
    "            \n",
    "            # create sub-folders for segregating tile images\n",
    "            parent_dir_level = path_level\n",
    "            directory_level_1, directory_level_2 = 'High_signal', 'Low_signal'\n",
    "            path_level_seg_1 = os.path.join(parent_dir_level, directory_level_1)\n",
    "            path_level_seg_2 = os.path.join(parent_dir_level, directory_level_2)\n",
    "            os.mkdir(path_level_seg_1)\n",
    "            os.mkdir(path_level_seg_2)\n",
    "            \n",
    "            # Saving image tiles at each level\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    tile_name = os.path.join(path_level, '%s_%d_%d' % (filename_noext, col, row))\n",
    "                    temp_tile = tiles.get_tile(j, (col, row))\n",
    "                    temp_tile_np = np.array(temp_tile.convert('RGB'))\n",
    "                    plt.imsave(tile_name + \".tiff\", temp_tile_np)\n",
    "                    \n",
    "#                     image = tiff.imread(tile_name)\n",
    "                    # use SD to filter\n",
    "                    if (temp_tile_np.std() >= 10):\n",
    "                        tile_name_1 = os.path.join(path_level_seg_1, '%s_%d_%d' % (filename_noext, col, row))\n",
    "                        plt.imsave(tile_name_1 + \".tiff\", temp_tile_np)\n",
    "                    else:\n",
    "                        tile_name_2 = os.path.join(path_level_seg_2, '%s_%d_%d' % (filename_noext, col, row))\n",
    "                        plt.imsave(tile_name_2 + \".tiff\", temp_tile_np)\n",
    "        print(f'WSI: {filename_noext} imageset created !')\n",
    "    else:\n",
    "        print('Folder already exists !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "50d53452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### Function to normalize HnE stained images - is this needed for DL ?\n",
    "# # # NOTE: does not work if image is blank\n",
    "\n",
    "# # https://youtu.be/tNfcvgPKgyU\n",
    "\n",
    "# # Original video on H&E topic: https://youtu.be/yUrwEYgZUsA\n",
    "\n",
    "# # Credit: https://github.com/bnsreenu/python_for_microscopists/blob/master/267_processing_whole_slide_images/normalize_HnE.py\n",
    "\n",
    "# '''\n",
    "# This code normalizes staining appearance of H&E stained images.\n",
    "# It also separates the hematoxylin and eosing stains in to different images. \n",
    "# Workflow based on the following papers:\n",
    "# A method for normalizing histology slides for quantitative analysis. \n",
    "# M. Macenko et al., ISBI 2009\n",
    "#     http://wwwx.cs.unc.edu/~mn/sites/default/files/macenko2009.pdf\n",
    "# Efficient nucleus detector in histopathology images. J.P. Vink et al., J Microscopy, 2013\n",
    "# Original MATLAB code:\n",
    "#     https://github.com/mitkovetta/staining-normalization/blob/master/normalizeStaining.m\n",
    " \n",
    "# Other useful references:\n",
    "#     https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5226799/\n",
    "#     https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169875\n",
    "# PROPOSED WORKFLOW:  \n",
    "    \n",
    "# Input: RGB image\n",
    "# Step 1: Convert RGB to OD (optical density)\n",
    "# Step 2: Remove data with OD intensity less than β\n",
    "# Step 3: Calculate  singular value decomposition (SVD) on the OD tuples\n",
    "# Step 4: Create plane from the SVD directions corresponding to the\n",
    "# two largest singular values\n",
    "# Step 5: Project data onto the plane, and normalize to unit length\n",
    "# Step 6: Calculate angle of each point wrt the first SVD direction\n",
    "# Step 7: Find robust extremes (αth and (100−α)th 7 percentiles) of the\n",
    "# angle\n",
    "# Step 8: Convert extreme values back to OD space\n",
    "# Output: Optimal Stain Vectors\n",
    "# '''\n",
    "\n",
    "# ############### INPUT RGB IMAGE #######################\n",
    "# #Using opencv to read images may bemore robust compared to using skimage\n",
    "# #but need to remember to convert BGR to RGB.\n",
    "# #Also, convert to float later on and normalize to between 0 and 1.\n",
    "\n",
    "# #Image downloaded from:\n",
    "# #https://pbs.twimg.com/media/C1MkrgQWQAASbdz.jpg\n",
    "# # img=cv2.imread('images/HnE_Image.jpg', 1)\n",
    "# # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Io = 240 # Transmitted light intensity, Normalizing factor for image intensities\n",
    "# # alpha = 1  #As recommend in the paper. tolerance for the pseudo-min and pseudo-max (default: 1)\n",
    "# # beta = 0.15 #As recommended in the paper. OD threshold for transparent pixels (default: 0.15)\n",
    "\n",
    "\n",
    "# def norm_HnE(img, Io=240, alpha=1, beta=0.15):\n",
    "\n",
    "\n",
    "#     ######## Step 1: Convert RGB to OD ###################\n",
    "#     ## reference H&E OD matrix.\n",
    "#     #Can be updated if you know the best values for your image. \n",
    "#     #Otherwise use the following default values. \n",
    "#     #Read the above referenced papers on this topic. \n",
    "#     HERef = np.array([[0.5626, 0.2159],\n",
    "#                       [0.7201, 0.8012],\n",
    "#                       [0.4062, 0.5581]])\n",
    "#     ### reference maximum stain concentrations for H&E\n",
    "#     maxCRef = np.array([1.9705, 1.0308])\n",
    "    \n",
    "    \n",
    "#     # extract the height, width and num of channels of image\n",
    "#     h, w, c = img.shape\n",
    "    \n",
    "#     # reshape image to multiple rows and 3 columns.\n",
    "#     #Num of rows depends on the image size (wxh)\n",
    "#     img = img.reshape((-1,3))\n",
    "    \n",
    "#     # calculate optical density\n",
    "#     # OD = −log10(I)  \n",
    "#     #OD = -np.log10(img+0.004)  #Use this when reading images with skimage\n",
    "#     #Adding 0.004 just to avoid log of zero. \n",
    "    \n",
    "#     OD = -np.log10((img.astype(np.float)+1)/Io) #Use this for opencv imread\n",
    "#     #Add 1 in case any pixels in the image have a value of 0 (log 0 is indeterminate)\n",
    "    \n",
    "    \n",
    "#     ############ Step 2: Remove data with OD intensity less than β ############\n",
    "#     # remove transparent pixels (clear region with no tissue)\n",
    "#     ODhat = OD[~np.any(OD < beta, axis=1)] #Returns an array where OD values are above beta\n",
    "#     #Check by printing ODhat.min()\n",
    "    \n",
    "#     ############# Step 3: Calculate SVD on the OD tuples ######################\n",
    "#     #Estimate covariance matrix of ODhat (transposed)\n",
    "#     # and then compute eigen values & eigenvectors.\n",
    "#     eigvals, eigvecs = np.linalg.eigh(np.cov(ODhat.T))\n",
    "    \n",
    "    \n",
    "#     ######## Step 4: Create plane from the SVD directions with two largest values ######\n",
    "#     #project on the plane spanned by the eigenvectors corresponding to the two \n",
    "#     # largest eigenvalues    \n",
    "#     That = ODhat.dot(eigvecs[:,1:3]) #Dot product\n",
    "    \n",
    "#     ############### Step 5: Project data onto the plane, and normalize to unit length ###########\n",
    "#     ############## Step 6: Calculate angle of each point wrt the first SVD direction ########\n",
    "#     #find the min and max vectors and project back to OD space\n",
    "#     phi = np.arctan2(That[:,1],That[:,0])\n",
    "    \n",
    "#     minPhi = np.percentile(phi, alpha)\n",
    "#     maxPhi = np.percentile(phi, 100-alpha)\n",
    "    \n",
    "#     vMin = eigvecs[:,1:3].dot(np.array([(np.cos(minPhi), np.sin(minPhi))]).T)\n",
    "#     vMax = eigvecs[:,1:3].dot(np.array([(np.cos(maxPhi), np.sin(maxPhi))]).T)\n",
    "    \n",
    "    \n",
    "#     # a heuristic to make the vector corresponding to hematoxylin first and the \n",
    "#     # one corresponding to eosin second\n",
    "#     if vMin[0] > vMax[0]:    \n",
    "#         HE = np.array((vMin[:,0], vMax[:,0])).T\n",
    "        \n",
    "#     else:\n",
    "#         HE = np.array((vMax[:,0], vMin[:,0])).T\n",
    "    \n",
    "    \n",
    "#     # rows correspond to channels (RGB), columns to OD values\n",
    "#     Y = np.reshape(OD, (-1, 3)).T\n",
    "    \n",
    "#     # determine concentrations of the individual stains\n",
    "#     C = np.linalg.lstsq(HE,Y, rcond=None)[0]\n",
    "    \n",
    "#     # normalize stain concentrations\n",
    "#     maxC = np.array([np.percentile(C[0,:], 99), np.percentile(C[1,:],99)])\n",
    "#     tmp = np.divide(maxC,maxCRef)\n",
    "#     C2 = np.divide(C,tmp[:, np.newaxis])\n",
    "    \n",
    "#     ###### Step 8: Convert extreme values back to OD space\n",
    "#     # recreate the normalized image using reference mixing matrix \n",
    "    \n",
    "#     Inorm = np.multiply(Io, np.exp(-HERef.dot(C2)))\n",
    "#     Inorm[Inorm>255] = 254\n",
    "#     Inorm = np.reshape(Inorm.T, (h, w, 3)).astype(np.uint8)  \n",
    "    \n",
    "#     # Separating H and E components\n",
    "#     H = np.multiply(Io, np.exp(np.expand_dims(-HERef[:,0], axis=1).dot(np.expand_dims(C2[0,:], axis=0))))\n",
    "#     H[H>255] = 254\n",
    "#     H = np.reshape(H.T, (h, w, 3)).astype(np.uint8)\n",
    "    \n",
    "#     E = np.multiply(Io, np.exp(np.expand_dims(-HERef[:,1], axis=1).dot(np.expand_dims(C2[1,:], axis=0))))\n",
    "#     E[E>255] = 254\n",
    "#     E = np.reshape(E.T, (h, w, 3)).astype(np.uint8)\n",
    "    \n",
    "#     return (Inorm, H, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Extract a small region from the large file (level 0)\n",
    "# #Let us extract a region from somewhere in the middle - coords 16k, 16k\n",
    "# #Extract 1024,1024 region\n",
    "# smaller_region = slide.read_region((10000,10000), 0, (5000,5000))\n",
    "# smaller_region_RGB = smaller_region.convert('RGB')\n",
    "# smaller_region_np = np.array(smaller_region_RGB)\n",
    "\n",
    "# # plt.axis('off')\n",
    "# # plt.imshow(smaller_region_np);\n",
    "\n",
    "# norm_img, H_img, E_img = norm_HnE(smaller_region_np, Io=240, alpha=1, beta=0.15)\n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.subplot(221)\n",
    "# plt.title('Original Image')\n",
    "# plt.imshow(smaller_region_np)\n",
    "# plt.subplot(222)\n",
    "# plt.title('Normalized Image')\n",
    "# plt.imshow(norm_img)\n",
    "# plt.subplot(223)\n",
    "# plt.title('H image')\n",
    "# plt.imshow(H_img)\n",
    "# plt.subplot(224)\n",
    "# plt.title('E image')\n",
    "# plt.imshow(E_img)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
